{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mura_Dataset_Densenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "18zZjssrOwzhNF6gR-SLF9eyt-bQ3-L4p",
      "authorship_tag": "ABX9TyOj9YFiuHlu7TbZ80WcH9nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "244060e10f774d5db3b395f619be9792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e31ec05e8a384178964c2ff1a0149db9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0c1ff25d4d44fb68ba3c4a5cfc65f87",
              "IPY_MODEL_e2660fc377fb45479c685ee29ce5be5a"
            ]
          }
        },
        "e31ec05e8a384178964c2ff1a0149db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0c1ff25d4d44fb68ba3c4a5cfc65f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c68eb72f47f249ed8fbbfb1b8be4b596",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 32342954,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32342954,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a81d00797fa42a29675d14702172340"
          }
        },
        "e2660fc377fb45479c685ee29ce5be5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a710ec16f7b4923bec0d2150034ab0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.8M/30.8M [00:00&lt;00:00, 102MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52ffd601ae3144c59106376cdff363a2"
          }
        },
        "c68eb72f47f249ed8fbbfb1b8be4b596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a81d00797fa42a29675d14702172340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a710ec16f7b4923bec0d2150034ab0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52ffd601ae3144c59106376cdff363a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UlkuTuncerKucuktas/MURA_DATASET_DENSENET/blob/main/Mura_Dataset_Densenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbKPNw6sHBUz"
      },
      "source": [
        "#Google Drive içerisindebulunan dataset arşivini colab üzerine açtım.\n",
        "!unzip \"/content/drive/My Drive/Mura_Dataset.rar\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEjOdjAgHH6B"
      },
      "source": [
        "#Data set içerisinde data path bulunan csv dosyalarını okudum.\n",
        "\n",
        "import pandas as pd\n",
        "TrainCsvFile = pd.read_csv(\"/content/MURA-v1.1/train_image_paths.csv\", names = [\"Path\"])\n",
        "ValidCsvFile = pd.read_csv(\"/content/MURA-v1.1/valid_image_paths.csv\",names = [\"Path\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-V_KM-WPCW-",
        "outputId": "620693e3-02fc-4a3d-e7d0-9034651be3c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.7.0+cu101\n",
            "Torchvision Version:  0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cmIlSD6HO9T",
        "outputId": "ac92ddac-d59f-4486-8b39-1359ddcc10b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "positivefilepath = \"/content/Image_Folder/train/positive\"#\n",
        "\n",
        "negativefilepath = \"/content/Image_Folder/train/negative\"\n",
        "\n",
        "validpositivefilepath = \"/content/Image_Folder/val/positive\"\n",
        "\n",
        "validnegativefilepath = \"/content/Image_Folder/val/negative\"\n",
        "\n",
        "\n",
        "#Pytorch kütüphenesinde bulunan ImageFolder dataframe hazırlama fonksiyonundan yararlanmak için\n",
        "#bizim elimizde bulunan data directory dizini üzerinde değişiklikler yapmak amacı ile yardımcı\n",
        "#fonksiyon\n",
        "def ImageFolderCreator(csvfilepath , positivefilepath , negativefilepath):\n",
        "  for i in tqdm(range(csvfilepath.shape[0])):\n",
        "    img = Image.open(\"/content/\" + csvfilepath[i])\n",
        "    img = img.resize((224,224))\n",
        "    img = img.convert('RGB')\n",
        "    \n",
        "    if \"positive\" in csvfilepath[i]:\n",
        "      img.save(positivefilepath + \"/img{}.png\".format(i),\"PNG\")\n",
        "    if \"negative\" in csvfilepath[i]:\n",
        "      img.save(negativefilepath + \"/img{}.png\".format(i),\"PNG\")\n",
        "\n",
        "ImageFolderCreator(TrainCsvFile['Path'],positivefilepath,negativefilepath)\n",
        "ImageFolderCreator(ValidCsvFile['Path'],validpositivefilepath,validnegativefilepath)\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 36808/36808 [10:00<00:00, 61.26it/s]\n",
            "100%|██████████| 3197/3197 [00:54<00:00, 59.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_xTErT5HXW6"
      },
      "source": [
        "\n",
        "#Image Folder için path\n",
        "data_dir = \"/content/Image_Folder/\"\n",
        "\n",
        "#Pytorch eğitimlerinde ağı fine tunin için yazılmış fonksiyonu kullanak amacı ile\n",
        "#gereken değişken\n",
        "model_name = \"densenet\"\n",
        "\n",
        "# Colab içerisinde bulunan ipynp dosyalarınıda class olarak saydığından dolayı 3\n",
        "# aslında gereken abnormal ve normal yani 2\n",
        "num_classes = 3\n",
        "\n",
        "# Batch size \n",
        "batch_size = 8\n",
        "\n",
        "#  epochs sayısı\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPPhfYe-L9LB"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Her epoch için valid ve train fazları var\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # modeli train moda alır\n",
        "            else:\n",
        "                model.eval()   # modeli eval moda alır\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # data içerisinde gezmek için.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, val_acc_history"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ziRm3nkMGSN"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNvrxmOCMJzV",
        "outputId": "c84c0dcf-c6d6-43b2-c850-f08163249077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "244060e10f774d5db3b395f619be9792",
            "e31ec05e8a384178964c2ff1a0149db9",
            "a0c1ff25d4d44fb68ba3c4a5cfc65f87",
            "e2660fc377fb45479c685ee29ce5be5a",
            "c68eb72f47f249ed8fbbfb1b8be4b596",
            "7a81d00797fa42a29675d14702172340",
            "4a710ec16f7b4923bec0d2150034ab0a",
            "52ffd601ae3144c59106376cdff363a2"
          ]
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    #Seçeceğimiz ağ için parametreleri fine tune eder\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)\n",
        "print(input_size)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "244060e10f774d5db3b395f619be9792",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=32342954.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n",
            "224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3a_v0BoRIqf",
        "outputId": "856bb815-0909-4e77-9736-9a95675b2ece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Data pre process işlemleri\n",
        "#Çoğu pre trained data 3,224,224 size ve normalize işlemi gerektirir\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Training ve validation datasetleri oluşturur\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Training ve validation dataloaderları oluşturur\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# GPU durumunu kontrol eder\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQS-Db9lRU_F",
        "outputId": "6ff6df86-5001-466e-aca5-e6ace062dc30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Modeli GPU ya oluşturur\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdLQOdykRadH",
        "outputId": "eee747f0-a8e1-494a-ca11-63c497abf1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs,is_inception=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6900 Acc: 0.6424\n",
            "val Loss: 0.6420 Acc: 0.6612\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.6782 Acc: 0.6520\n",
            "val Loss: 0.7892 Acc: 0.6225\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6823 Acc: 0.6487\n",
            "val Loss: 0.6183 Acc: 0.6797\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6771 Acc: 0.6534\n",
            "val Loss: 0.8591 Acc: 0.5993\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.6836 Acc: 0.6487\n",
            "val Loss: 0.6690 Acc: 0.6544\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.6779 Acc: 0.6520\n",
            "val Loss: 0.6461 Acc: 0.6666\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.6841 Acc: 0.6509\n",
            "val Loss: 0.6362 Acc: 0.6778\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.6834 Acc: 0.6496\n",
            "val Loss: 0.6491 Acc: 0.6681\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.6781 Acc: 0.6502\n",
            "val Loss: 0.7550 Acc: 0.6303\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.6786 Acc: 0.6536\n",
            "val Loss: 0.8316 Acc: 0.6231\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.6919 Acc: 0.6460\n",
            "val Loss: 0.6540 Acc: 0.6763\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.6763 Acc: 0.6506\n",
            "val Loss: 0.6388 Acc: 0.6606\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.6895 Acc: 0.6532\n",
            "val Loss: 0.9177 Acc: 0.5887\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.6818 Acc: 0.6501\n",
            "val Loss: 0.6405 Acc: 0.6672\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.6856 Acc: 0.6492\n",
            "val Loss: 0.6190 Acc: 0.6841\n",
            "\n",
            "Training complete in 135m 1s\n",
            "Best val Acc: 0.684079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVosid0-4X-4"
      },
      "source": [
        "historyarr = []\n",
        "\n",
        "[historyarr.append(hist[i].item()) for i in range(15)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqyv6AHd68Cj",
        "outputId": "45633c52-dc01-43f4-bb0e-d9d291772920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),historyarr,label=\"Model\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}